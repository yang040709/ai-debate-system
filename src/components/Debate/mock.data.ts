import { DebateList } from './Debate.d'
export const mockDebateList: DebateList = [
  {
    avatar: '/avatar.png',
    name: '用户',
    datetime: '2023-12-12 10:00',
    content:
      '我认为人工智能的发展应该受到严格限制。现在的AI技术发展太快，已经对很多传统行业造成了冲击，导致大量人员失业。我们应该优先考虑人类的就业问题，而不是盲目追求技术进步。技术应该为人类服务，而不是取代人类。',
    role: 'user',
  },
  {
    avatar: '/ai_avatar.png',
    name: 'AI助手',
    datetime: '2023-12-12 10:05',
    content:
      '## 技术进步与就业的关系\n\n人工智能确实会改变就业结构，但历史表明技术进步**创造的新岗位**往往多于它取代的旧岗位。例如：\n\n- **工业革命**时期，机器取代了手工劳动，但创造了工厂工人、工程师等新职业\n- **IT革命**淘汰了一些文职工作，但催生了程序员、数据分析师等职位\n\n关键不在于限制AI发展，而在于：\n1. 加强职业培训和教育改革\n2. 建立完善的社会保障体系\n3. 推动人机协作的新工作模式',
    role: 'assistant',
  },
  {
    avatar: '/avatar.png',
    name: '用户',
    datetime: '2023-12-12 10:10',
    content:
      '但是现在的AI发展速度远远超过了过去的技术革命。ChatGPT这样的工具在短短几个月内就影响了数亿人的工作方式。这种变化太快了，社会根本来不及适应。而且AI的决策过程不透明，存在严重的黑箱问题，在医疗、金融等关键领域应用风险太大。',
    role: 'user',
  },
  {
    avatar: '/ai_avatar.png',
    name: 'AI助手',
    datetime: '2023-12-12 10:15',
    content:
      '## 应对AI加速发展的策略\n\n您提到的速度问题确实值得关注，但解决方案应该是**适应性管理**而非简单限制：\n\n### 可解释AI(XAI)的发展\n- 当前已有**LIME、SHAP**等技术提升模型可解释性\n- 欧盟AI法案要求高风险AI系统必须提供决策解释\n\n### 渐进式应用策略\n```\n阶段1：辅助决策 → 阶段2：人机协同 → 阶段3：有限自主\n```\n\n这种渐进路径能给社会足够的适应时间，同时享受AI带来的效率提升。',
    role: 'assistant',
  },
  {
    avatar: '/avatar.png',
    name: '用户',
    datetime: '2023-12-12 10:20',
    content:
      '我担心的是AI的价值观对齐问题。现在的AI大多由少数科技巨头控制，它们的训练数据可能包含偏见，决策逻辑可能不符合人类利益。如果AI在关键领域做决策，谁来保证它的公平性？如果出现错误，责任又该由谁承担？',
    role: 'user',
  },
  {
    avatar: '/ai_avatar.png',
    name: 'AI助手',
    datetime: '2023-12-12 10:25',
    content:
      '## AI治理与责任框架\n\n### 多方参与的治理体系\n| 参与者 | 职责 |\n|-------|------|\n| 政府机构 | 制定标准和监管框架 |\n| 科研机构 | 研发价值观对齐技术 |\n| 民间社会 | 监督和评估AI影响 |\n\n### 技术解决方案进展\n- **宪法AI**：让AI根据明确原则进行自我修正\n- **红队测试**：主动发现和修复价值观偏差\n- **第三方审计**：独立评估AI系统的公平性\n\n责任认定需要新的法律框架，但技术上已有很多积极探索。',
    role: 'assistant',
  },
  {
    avatar: '/avatar.png',
    name: '用户',
    datetime: '2023-12-12 10:30',
    content:
      '另一个担忧是AI的安全性。如果强大的AI系统被恶意使用，比如用于制造生物武器、发动网络攻击，或者用于大规模监控和社会控制，后果将不堪设想。我们现在是否有足够的安全措施来防止这些风险？',
    role: 'user',
  },
  {
    avatar: '/ai_avatar.png',
    name: 'AI助手',
    datetime: '2023-12-12 10:35',
    content:
      '## AI安全的多层次防护体系\n\n### 技术层防护\n- **模型权重保护**：防止模型被盗用或篡改\n- **输出过滤**：实时检测和阻断恶意内容生成\n- **访问控制**：基于身份和用途的精细化权限管理\n\n### 政策层保障\n> "安全不是产品特性，而是设计基础" —— AI安全基本原则\n\n1. **研发准入制度**：对高风险AI研发实行许可证管理\n2. **全球合作机制**：建立跨国AI安全信息共享平台  \n3. **漏洞奖励计划**：鼓励白帽黑客发现和报告安全漏洞\n\n安全是AI发展的前提，需要技术与治理协同推进。',
    role: 'assistant',
  },
  {
    avatar: '/avatar.png',
    name: '用户',
    datetime: '2023-12-12 10:40',
    content:
      '我承认AI有很多潜在好处，但在伦理层面的担忧仍然存在。比如AI生成内容的版权问题，深度伪造技术对个人声誉的威胁，还有算法推荐造成的信息茧房效应。这些不是技术问题，而是社会伦理问题，我们需要在技术发展之前就先解决好这些伦理困境。',
    role: 'user',
  },
  {
    avatar: '/ai_avatar.png',
    name: 'AI助手',
    datetime: '2023-12-12 10:45',
    content: '## 构建AI伦理实践框架\n\n当前主要伦理挑战及应对 ',
    role: 'assistant',
  },
]
